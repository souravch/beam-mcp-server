service:
  name: beam-mcp
  type: beam
  description: Apache Beam MCP Server
  version: 1.0.0

default_runner: direct

runners:
  flink:
    enabled: true
    jobmanager_url: http://localhost:8081
    flink_master: localhost:8081
    rest_url: http://localhost:8081
    jar_path: null  # Path to the Flink job jar (for non-portable pipelines)
    # Pipeline options for Flink runner
    pipeline_options:
      parallelism: 4
      checkpointing_interval: 10000  # milliseconds
      state_backend: "memory"  # "memory", "filesystem", or "rocksdb"
      tmp_dir: "/tmp/beam-flink-tmp"
      state_backend_path: "/tmp/beam-flink-state"
      savepoint_path: "/tmp/beam-flink-savepoints"
      auto_watermark_interval: 1000  # milliseconds
      streaming: false  # Set to true for streaming jobs
      
  direct:
    enabled: true
    pipeline_options:
      direct_num_workers: 4
      direct_running_mode: multi_threading
      temp_location: /tmp/beam-direct-temp
      save_main_session: true

  # Adding Spark runner configuration
  spark:
    enabled: false  # Disabled until Spark dependencies are installed
    spark_master: local[*]  # Use "local[*]" for local testing, or Spark master URL for cluster
    spark_home: null  # Will be auto-detected if installed
    app_name: beam-mcp-spark
    rest_api_port: 4040
    pipeline_options:
      spark_job_name: beam-mcp-spark-job
      spark_executor_instances: 2
      spark_executor_cores: 2
      spark_executor_memory: 1g
      spark_driver_memory: 1g
      temp_location: /tmp/beam-spark-temp
      save_main_session: true

  # Adding Dataflow runner configuration for future use (disabled by default)
  dataflow:
    enabled: false
    pipeline_options:
      project: your-gcp-project-id  # Must be set for Dataflow jobs
      region: us-central1
      zone: us-central1-a
      staging_location: gs://your-bucket/staging
      temp_location: gs://your-bucket/temp
      network: default
      subnetwork: regions/us-central1/subnetworks/default
      max_workers: 4
      autoscaling_algorithm: THROUGHPUT_BASED
      disk_size_gb: 30
      worker_machine_type: n1-standard-2
      save_main_session: true
      experiments: ["use_runner_v2"]
      service_account_email: null

interfaces:
  jobs:
    enabled: true
  
  metrics:
    enabled: true
  
  logs:
    enabled: true
  
  savepoints:
    enabled: true
    default_savepoint_dir: /tmp/beam-savepoints

mcp:
  version: 1.0
  server_name: beam-mcp-server
  provider: apache
  log_level: DEBUG  # Set to DEBUG to get more information

gcp:
  project_id: your-gcp-project-id  # Will be ignored since Dataflow is disabled
  region: us-central1 